{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed60df4f-cc51-4d7a-90cd-aaf848e7416a",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook guides you through the setup and execution of the GOLD layer in your data pipeline using Snowflake and Iceberg tables. The GOLD layer focuses on curating aggregated and analytics-ready tables by leveraging the curated data from the SILVER and BRONZE layers.\n",
    "\n",
    "You will:\n",
    "- Import required Python packages and establish a Snowflake session.\n",
    "- Set up user-specific variables, roles, databases, and schemas for the GOLD layer.\n",
    "- Create dynamic Iceberg tables for key business entities and aggregations.\n",
    "- Join and enrich data from the SILVER and BRONZE layers to produce final reporting tables.\n",
    "- Create summary views for analytics and dashboarding.\n",
    "\n",
    "Follow the instructions and code cells to complete the GOLD pipeline and prepare your data for business intelligence and advanced analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5221c51-7199-4553-8b91-53178e7844d7",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "# Set User Number\n",
    "\n",
    "Update the cell below with your unique user number for this lab. This ensures that all resources you create are isolated and do not conflict with those of other users.\n",
    "\n",
    "**Usernum = '999'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "usernum = str('<INSERT USER NUMBER>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcfd39-612b-4741-b6cb-c15c22937cd0",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": [
    "# Set User-Specific Variables\n",
    "\n",
    "This section defines variables for your username, role, database, and schema. These variables will be used throughout the notebook to ensure all operations are performed in your dedicated environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SET USERNAME = 'HOL_USER_' || {{usernum}};\n",
    "SELECT $USERNAME;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8f716-da11-41c5-ad47-afd0e1d65ba2",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "SET HOLROLE = $USERNAME || '_FULL_ROLE';\n",
    "SET DB_NAME = $USERNAME || '_DB';\n",
    "SET SCHEMANAME = 'GOLD';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55825442-d156-4c62-9a5f-554534fe29e1",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "USE ROLE IDENTIFIER($HOLROLE);\n",
    "USE DATABASE IDENTIFIER($DB_NAME);\n",
    "USE SCHEMA IDENTIFIER($SCHEMANAME);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274cd97b",
   "metadata": {},
   "source": [
    "# Creating the SCHEDULE Table\n",
    "\n",
    "This step creates a dynamic Iceberg table named `SCHEDULE` in the GOLD schema. The table is populated by selecting the latest schedule record for each unique schedule key from the SILVER layer, ensuring only the most relevant schedule information is retained for analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ce60d-d26d-4e98-bdfc-5fc0c7b34c71",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import row_number, col,desc\n",
    "from snowflake.snowpark.window import Window\n",
    "# Read the table\n",
    "df = session.table(\"silver.schedule_00\")\n",
    "\n",
    "# Define the window specification\n",
    "window_spec = Window.partition_by(\"schedule_key\").order_by(\"ORIGIN_LAT_LON\")\n",
    "\n",
    "# Add row number and filter\n",
    "result_df = df.with_column(\"rn\", row_number().over(window_spec)) \\\n",
    "              .filter(col(\"rn\") == 1) \\\n",
    "              .drop(\"rn\")\n",
    "\n",
    "sch_iceberg_config = {\n",
    "    \"external_volume\": \"iceberg_hol_gold_vol\",\n",
    "    \"catalog\": \"SNOWFLAKE\",\n",
    "    \"base_location\": f\"hol_user_{usernum}/schedule/\",\n",
    "    \"catalog_sync\": \"iceberg_hol_oc_int\"\n",
    "}\n",
    "\n",
    "result_df.write.save_as_table(\"schedule\",mode='overwrite',iceberg_config = sch_iceberg_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f15bd",
   "metadata": {},
   "source": [
    "# Creating the TRAIN_ACTIVATIONS Table\n",
    "\n",
    "This cell creates a dynamic Iceberg table named `TRAIN_ACTIVATIONS` by selecting the most recent activation event for each train from the SILVER layer. This ensures that only the latest activation record per train is available for downstream analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa186a-7560-4686-b843-71777ff93824",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# Read the table\n",
    "df = session.table(\"silver.train_activations_01\")\n",
    "\n",
    "# Define the window specification\n",
    "window_spec = Window.partition_by(\"TRAIN_ID\").order_by(desc(\"CREATION_TIMESTAMP\"))\n",
    "\n",
    "# Add row number and filter\n",
    "ta_result_df = df.with_column(\"rn\", row_number().over(window_spec)) \\\n",
    "              .filter(col(\"rn\") == 1) \\\n",
    "              .drop(\"rn\")\n",
    "\n",
    "ta_iceberg_config = {\n",
    "    \"external_volume\": \"iceberg_hol_gold_vol\",\n",
    "    \"catalog\": \"SNOWFLAKE\",\n",
    "    \"base_location\": f\"hol_user_{usernum}/schedule/\",\n",
    "    \"catalog_sync\": \"iceberg_hol_oc_int\"\n",
    "}\n",
    "\n",
    "ta_result_df.write.save_as_table(\"TRAIN_ACTIVATIONS\",mode='overwrite',iceberg_config = ta_iceberg_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc6d0a",
   "metadata": {},
   "source": [
    "# Creating the TRAIN_MOVEMENTS Table\n",
    "\n",
    "This step creates a dynamic Iceberg table named `TRAIN_MOVEMENTS` by joining movement events from the SILVER layer with activation, schedule, and location data. The resulting table provides a comprehensive, enriched view of each train movement, including schedule, route, and geospatial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528973e-78b0-4c4d-9665-1662819eb0cd",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE DYNAMIC ICEBERG TABLE TRAIN_MOVEMENTS\n",
    "  TARGET_LAG = '1 minute'\n",
    "  WAREHOUSE = hol_user_{{usernum}}_wh\n",
    "  EXTERNAL_VOLUME= 'iceberg_hol_gold_vol'\n",
    "  CATALOG = 'SNOWFLAKE'\n",
    "  BASE_LOCATION = 'hol_user_{{usernum}}/train_movements/'\n",
    "  CATALOG_SYNC = iceberg_hol_oc_int\n",
    "AS\n",
    "SELECT  TM.MSG_KEY AS MSG_KEY,\n",
    "        TM.MSG_HEADER AS MSG_HEADER,\n",
    "        TM.EVENT_TYPE AS EVENT_TYPE,\n",
    "        TM.GBTT_TIMESTAMP AS GBTT_TIMESTAMP,\n",
    "        TM.ORIGINAL_LOC_STANOX AS ORIGINAL_LOC_STANOX,\n",
    "        TM.PLANNED_TIMESTAMP AS PLANNED_TIMESTAMP,\n",
    "        TM.TIMETABLE_VARIATION AS TIMETABLE_VARIATION,\n",
    "        TM.ORIGINAL_LOC_TIMESTAMP AS ORIGINAL_LOC_TIMESTAMP,\n",
    "        TM.CURRENT_TRAIN_ID AS CURRENT_TRAIN_ID,\n",
    "        TM.DELAY_MONITORING_POINT AS DELAY_MONITORING_POINT,\n",
    "        TM.NEXT_REPORT_RUN_TIME AS NEXT_REPORT_RUN_TIME,\n",
    "        TM.REPORTING_STANOX AS REPORTING_STANOX,\n",
    "        TM.ACTUAL_TIMESTAMP AS ACTUAL_TIMESTAMP,\n",
    "        TM.CORRECTION_IND AS CORRECTION_IND,\n",
    "        TM.EVENT_SOURCE AS EVENT_SOURCE,\n",
    "        TM.TRAIN_FILE_ADDRESS AS TRAIN_FILE_ADDRESS,\n",
    "        TM.PLATFORM AS PLATFORM,\n",
    "        TM.DIVISION_CODE AS DIVISION_CODE,\n",
    "        TM.TRAIN_TERMINATED AS TRAIN_TERMINATED,\n",
    "        TM.TRAIN_ID AS TRAIN_ID,\n",
    "        TM.OFFROUTE_IND AS OFFROUTE_IND,\n",
    "        TM.VARIATION AS VARIATION,\n",
    "        TM.LATE_IND AS LATE_IND,\n",
    "        TM.VARIATION_STATUS AS VARIATION_STATUS,\n",
    "        TM.TRAIN_SERVICE_CODE AS TRAIN_SERVICE_CODE,\n",
    "        TM.TOC_ID AS TOC_ID,\n",
    "        TM.TOC AS TOC,\n",
    "        TM.LOC_STANOX AS LOC_STANOX,\n",
    "        L.DESCRIPTION AS MVT_DESCRIPTION,\n",
    "        object_construct_keep_null('long',L.LONGITUDE, 'lat',L.LATITUDE)::OBJECT(long float, lat float) AS MVT_LAT_LON,\n",
    "        TM.AUTO_EXPECTED AS AUTO_EXPECTED,\n",
    "        TM.DIRECTION_IND AS DIRECTION_IND,\n",
    "        TM.ROUTE AS ROUTE,\n",
    "        TM.PLANNED_EVENT_TYPE AS PLANNED_EVENT_TYPE,\n",
    "        TM.NEXT_REPORT_STANOX AS NEXT_REPORT_STANOX,\n",
    "        TM.LINE_IND AS LINE_IND,\n",
    "        TA.SCHEDULE_SOURCE AS SCHEDULE_SOURCE,\n",
    "        TA.TP_ORIGIN_TIMESTAMP AS TP_ORIGIN_TIMESTAMP,\n",
    "        TA.SCHEDULE_TYPE AS SCHEDULE_TYPE,\n",
    "        TA.CREATION_TIMESTAMP AS CREATION_TIMESTAMP,\n",
    "        TA.ORIGIN_DEP_TIMESTAMP AS ORIGIN_DEP_TIMESTAMP,\n",
    "        TA.D1266_RECORD_NUMBER AS D1266_RECORD_NUMBER,\n",
    "        TA.TRAIN_SERVICE_CODE AS TRAIN_SERVICE_CODE_02,\n",
    "        TA.SCHED_ORIGIN_STANOX AS SCHED_ORIGIN_STANOX,\n",
    "        TA.TRAIN_UID AS TRAIN_UID,\n",
    "        TA.TRAIN_CALL_MODE AS TRAIN_CALL_MODE,\n",
    "        TA.TP_ORIGIN_STANOX AS TP_ORIGIN_STANOX,\n",
    "        TA.SCHEDULE_WTT_ID AS SCHEDULE_WTT_ID,\n",
    "        TA.TRAIN_CALL_TYPE AS TRAIN_CALL_TYPE,\n",
    "        TA.SCHEDULE_END_DATE AS SCHEDULE_END_DATE,\n",
    "        COALESCE(TA.SCHEDULE_KEY,'no_schedule_activation_found') AS SCHEDULE_KEY,\n",
    "        TA.SCHED_ORIGIN_DESC AS SCHED_ORIGIN_DESC,\n",
    "        SCH.CIF_TRAIN_UID AS CIF_TRAIN_UID,\n",
    "        SCH.NUM_STOPS AS SCHEDULE_NUM_STOPS,\n",
    "        SCH.SCHEDULE_START_DATE AS SCHEDULE_START_DATE,\n",
    "        SCH.CIF_STP_INDICATOR AS CIF_STP_INDICATOR,\n",
    "        SCH.ATOC_CODE AS ATOC_CODE,\n",
    "        SCH.TRAIN_STATUS AS TRAIN_STATUS,\n",
    "        SCH.POWER_TYPE AS POWER_TYPE,\n",
    "        SCH.SEATING_CLASSES AS SEATING_CLASSES,\n",
    "        SCH.RESERVATIONS AS RESERVATIONS,\n",
    "        SCH.SLEEPING_ACCOMODATION AS SLEEPING_ACCOMODATION,\n",
    "        SCH.TRAIN_CATEGORY AS TRAIN_CATEGORY,\n",
    "        SCH.ORIGIN_TIPLOC_CODE AS ORIGIN_TIPLOC_CODE,\n",
    "          SCH.ORIGIN_DESCRIPTION                                    AS ORIGIN_DESCRIPTION,\n",
    "          SCH.ORIGIN_LAT_LON                                    AS ORIGIN_LAT_LON,\n",
    "        SCH.ORIGIN_PUBLIC_DEPARTURE_TIME AS ORIGIN_PUBLIC_DEPARTURE_TIME,\n",
    "        SCH.ORIGIN_PLATFORM AS ORIGIN_PLATFORM,\n",
    "        SCH.DESTINATION_TIPLOC_CODE AS DESTINATION_TIPLOC_CODE,\n",
    "          SCH.DESTINATION_DESCRIPTION                               AS DESTINATION_DESCRIPTION,\n",
    "          SCH.DESTINATION_LAT_LON                               AS DESTINATION_LAT_LON,\n",
    "        SCH.DESTINATION_PUBLIC_ARRIVAL_TIME AS DESTINATION_PUBLIC_ARRIVAL_TIME,\n",
    "        SCH.DESTINATION_PLATFORM AS DESTINATION_PLATFORM  \n",
    "  FROM SILVER.TRAIN_MOVEMENTS_00 TM\n",
    "      LEFT JOIN TRAIN_ACTIVATIONS TA\n",
    "        ON TM.TRAIN_ID = TA.TRAIN_ID\n",
    "      LEFT JOIN BRONZE.LOCATIONS_RAW L\n",
    "         ON TM.loc_stanox = L.STANOX\n",
    "      LEFT JOIN \n",
    "        SCHEDULE SCH \n",
    "        ON COALESCE(TA.SCHEDULE_KEY,'no_schedule_activation_found') = SCH.SCHEDULE_KEY;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d37eb",
   "metadata": {},
   "source": [
    "# Creating the TRAIN_CANCELLATIONS Table\n",
    "\n",
    "This cell creates a dynamic Iceberg table named `TRAIN_CANCELLATIONS` by joining cancellation events from the SILVER layer with activation, schedule, and location reference data. The resulting table provides enriched cancellation event details for analytics and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2e156-e90a-4e19-afd0-b4bfd4c5006a",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE ICEBERG TABLE TRAIN_CANCELLATIONS(\n",
    "    \"MSG_HEADER\" STRING(16777216),\n",
    "    \"TRAIN_FILE_ADDRESS\" STRING(16777216),\n",
    "    \"TRAIN_SERVICE_CODE\" STRING(16777216),\n",
    "    \"ORIG_LOC_STANOX\" STRING(16777216),\n",
    "    \"TOC_ID\" STRING(16777216),\n",
    "    \"TOC\" STRING(16777216),\n",
    "    \"DEP_TIMESTAMP\" BIGINT,\n",
    "    \"DIVISION_CODE\" BIGINT,\n",
    "    \"LOC_STANOX\" STRING(16777216),\n",
    "    \"CANX_TIMESTAMP\" BIGINT,\n",
    "    \"CANX_REASON_CODE\" STRING(16777216),\n",
    "    \"CANX_REASON\" STRING(16777216),\n",
    "    \"CANCELLATION_LOCATION\" STRING(16777216),\n",
    "    \"CANCELLATION_LAT_LON\" OBJECT(long FLOAT, lat FLOAT),\n",
    "    \"TRAIN_ID\" STRING(16777216),\n",
    "    \"ORIG_LOC_TIMESTAMP\" TIMESTAMP_NTZ,\n",
    "    \"CANX_TYPE\" STRING(16777216),\n",
    "    \"SCHEDULE_SOURCE\" STRING(16777216),\n",
    "    \"TP_ORIGIN_TIMESTAMP\" TIMESTAMP_NTZ,\n",
    "    \"SCHEDULE_TYPE\" STRING(16777216),\n",
    "    \"CREATION_TIMESTAMP\" TIMESTAMP_NTZ,\n",
    "    \"ORIGIN_DEP_TIMESTAMP\" TIMESTAMP_NTZ,\n",
    "    \"D1266_RECORD_NUMBER\" STRING(16777216),\n",
    "    \"TRAIN_SERVICE_CODE_02\" STRING(16777216),\n",
    "    \"SCHED_ORIGIN_STANOX\" STRING(16777216),\n",
    "    \"TRAIN_UID\" STRING(16777216),\n",
    "    \"TRAIN_CALL_MODE\" STRING(16777216),\n",
    "    \"TP_ORIGIN_STANOX\" STRING(16777216),\n",
    "    \"SCHEDULE_WTT_ID\" STRING(16777216),\n",
    "    \"TRAIN_CALL_TYPE\" STRING(16777216),\n",
    "    \"SCHEDULE_END_DATE\" DATE,\n",
    "    \"SCHEDULE_KEY\" STRING(16777216) NOT NULL,\n",
    "    \"SCHED_ORIGIN_DESC\" STRING(16777216),\n",
    "    \"CIF_TRAIN_UID\" STRING(16777216),\n",
    "    \"SCHEDULE_START_DATE\" DATE,\n",
    "    \"CIF_STP_INDICATOR\" STRING(16777216),\n",
    "    \"ATOC_CODE\" STRING(16777216),\n",
    "    \"TRAIN_STATUS\" STRING(16777216),\n",
    "    \"POWER_TYPE\" STRING(16777216),\n",
    "    \"SEATING_CLASSES\" STRING(16777216),\n",
    "    \"RESERVATIONS\" STRING(16777216),\n",
    "    \"SLEEPING_ACCOMODATION\" STRING(16777216),\n",
    "    \"TRAIN_CATEGORY\" STRING(16777216),\n",
    "    \"ORIGIN_TIPLOC_CODE\" STRING(16777216),\n",
    "    \"ORIGIN_DESCRIPTION\" STRING(16777216),\n",
    "    \"ORIGIN_LAT_LON\" DOUBLE,\n",
    "    \"ORIGIN_PUBLIC_DEPARTURE_TIME\" STRING(16777216),\n",
    "    \"ORIGIN_PLATFORM\" STRING(16777216),\n",
    "    \"DESTINATION_TIPLOC_CODE\" STRING(16777216),\n",
    "    \"DESTINATION_DESCRIPTION\" STRING(16777216),\n",
    "    \"DESTINATION_LAT_LON\" DOUBLE,\n",
    "    \"DESTINATION_PUBLIC_ARRIVAL_TIME\" STRING(16777216),\n",
    "    \"DESTINATION_PLATFORM\" STRING(16777216)\n",
    ") \n",
    "EXTERNAL_VOLUME = 'iceberg_hol_gold_vol' \n",
    "CATALOG = 'SNOWFLAKE' \n",
    "BASE_LOCATION = 'hol_user_{{usernum}}/train_cancellations/' \n",
    "CATALOG_SYNC = 'iceberg_hol_oc_int' ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236421ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark imports\n",
    "from snowflake.snowpark.functions import col, coalesce, object_construct_keep_null, to_object, lit, sql_expr\n",
    "from snowflake.snowpark.types import FloatType, StructField, StructType, MapType\n",
    "\n",
    "# Load source DataFrames\n",
    "tc = session.table(\"SILVER.TRAIN_CANCELLATIONS_00\")\n",
    "l = session.table(\"BRONZE.LOCATIONS_RAW\")\n",
    "c = session.table(\"SILVER.CANCEL_CODE_REFERENCES_00\")\n",
    "ta = session.table(\"TRAIN_ACTIVATIONS\")\n",
    "sch = session.table(\"SCHEDULE\")\n",
    "\n",
    "\n",
    "df_tc_l = (\n",
    "            tc.join(l,col(\"LOC_STANOX\") == col(\"STANOX\"), how=\"left\")\n",
    "                .join(c, col(\"CANX_REASON_CODE\") == col(\"CODE\"), how=\"left\")\n",
    "                .join(sch,  coalesce(col(\"SCHEDULE_KEY\"), lit(\"X\")) == col(\"SCHEDULE_KEY\"), how=\"left\",rsuffix = '_sch')\n",
    "                .join(ta,  col(\"TRAIN_ID_TA\") == col(\"TRAIN_ID\"), how=\"left\",rsuffix = '_TA')\n",
    "                .select(\n",
    "                col(\"MSG_HEADER\").alias(\"MSG_HEADER\"),\n",
    "                col(\"TRAIN_FILE_ADDRESS\").alias(\"TRAIN_FILE_ADDRESS\"),\n",
    "                col(\"TRAIN_SERVICE_CODE\").alias(\"TRAIN_SERVICE_CODE\"),\n",
    "                col(\"ORIG_LOC_STANOX\").alias(\"ORIG_LOC_STANOX\"),\n",
    "                col(\"TOC_ID\").alias(\"TOC_ID\"),\n",
    "                col(\"TOC\").alias(\"TOC\"),\n",
    "                col(\"DEP_TIMESTAMP\").alias(\"DEP_TIMESTAMP\"),\n",
    "                col(\"DIVISION_CODE\").alias(\"DIVISION_CODE\"),\n",
    "                col(\"LOC_STANOX\").alias(\"LOC_STANOX\"),\n",
    "                col(\"CANX_TIMESTAMP\").alias(\"CANX_TIMESTAMP\"),\n",
    "                col(\"CANX_REASON_CODE\").alias(\"CANX_REASON_CODE\"),\n",
    "                col(\"CODE\").alias(\"CANX_REASON\"),\n",
    "                col(\"DESCRIPTION\").alias(\"CANCELLATION_LOCATION\"),\n",
    "                sql_expr(\"object_construct_keep_null('long',LONGITUDE,'lat',LATITUDE)::OBJECT(long FLOAT, lat FLOAT)\").alias(\"CANCELLATION_LAT_LON\"),    \n",
    "                #object_construct_keep_null(lit(\"long\"), col(\"LONGITUDE\"), lit(\"lat\"), col(\"LATITUDE\")).cast(MapType([StructField(\"long\", FloatType()), StructField(\"lat\", FloatType())])).alias(\"CANCELLATION_LAT_LON\"),\n",
    "                col(\"TRAIN_ID\").alias(\"TRAIN_ID\"),\n",
    "                col(\"ORIG_LOC_TIMESTAMP\").alias(\"ORIG_LOC_TIMESTAMP\"),\n",
    "                col(\"CANX_TYPE\").alias(\"CANX_TYPE\"),\n",
    "                col(\"SCHEDULE_SOURCE\").alias(\"SCHEDULE_SOURCE\"),\n",
    "                col(\"TP_ORIGIN_TIMESTAMP\").alias(\"TP_ORIGIN_TIMESTAMP\"),\n",
    "                col(\"SCHEDULE_TYPE\").alias(\"SCHEDULE_TYPE\"),\n",
    "                col(\"CREATION_TIMESTAMP\").alias(\"CREATION_TIMESTAMP\"),\n",
    "                col(\"ORIGIN_DEP_TIMESTAMP\").alias(\"ORIGIN_DEP_TIMESTAMP\"),\n",
    "                col(\"D1266_RECORD_NUMBER\").alias(\"D1266_RECORD_NUMBER\"),\n",
    "                col(\"TRAIN_SERVICE_CODE\").alias(\"TRAIN_SERVICE_CODE_02\"),\n",
    "                col(\"SCHED_ORIGIN_STANOX\").alias(\"SCHED_ORIGIN_STANOX\"),\n",
    "                col(\"TRAIN_UID\").alias(\"TRAIN_UID\"),\n",
    "                col(\"TRAIN_CALL_MODE\").alias(\"TRAIN_CALL_MODE\"),\n",
    "                col(\"TP_ORIGIN_STANOX\").alias(\"TP_ORIGIN_STANOX\"),\n",
    "                col(\"SCHEDULE_WTT_ID\").alias(\"SCHEDULE_WTT_ID\"),\n",
    "                col(\"TRAIN_CALL_TYPE\").alias(\"TRAIN_CALL_TYPE\"),\n",
    "                col(\"SCHEDULE_END_DATE\").alias(\"SCHEDULE_END_DATE\"),\n",
    "                coalesce(col(\"SCHEDULE_KEY\"), lit(\"no_schedule_found\")).alias(\"SCHEDULE_KEY\"),\n",
    "                col(\"SCHED_ORIGIN_DESC\").alias(\"SCHED_ORIGIN_DESC\"),\n",
    "                col(\"CIF_TRAIN_UID\").alias(\"CIF_TRAIN_UID\"),\n",
    "                col(\"SCHEDULE_START_DATE\").alias(\"SCHEDULE_START_DATE\"),\n",
    "                col(\"CIF_STP_INDICATOR\").alias(\"CIF_STP_INDICATOR\"),\n",
    "                col(\"ATOC_CODE\").alias(\"ATOC_CODE\"),\n",
    "                col(\"TRAIN_STATUS\").alias(\"TRAIN_STATUS\"),\n",
    "                col(\"POWER_TYPE\").alias(\"POWER_TYPE\"),\n",
    "                col(\"SEATING_CLASSES\").alias(\"SEATING_CLASSES\"),\n",
    "                col(\"RESERVATIONS\").alias(\"RESERVATIONS\"),\n",
    "                col(\"SLEEPING_ACCOMODATION\").alias(\"SLEEPING_ACCOMODATION\"),\n",
    "                col(\"TRAIN_CATEGORY\").alias(\"TRAIN_CATEGORY\"),\n",
    "                col(\"ORIGIN_TIPLOC_CODE\").alias(\"ORIGIN_TIPLOC_CODE\"),\n",
    "                col(\"ORIGIN_DESCRIPTION\").alias(\"ORIGIN_DESCRIPTION\"),\n",
    "                col(\"ORIGIN_LAT_LON\").alias(\"ORIGIN_LAT_LON\"),\n",
    "                col(\"ORIGIN_PUBLIC_DEPARTURE_TIME\").alias(\"ORIGIN_PUBLIC_DEPARTURE_TIME\"),\n",
    "                col(\"ORIGIN_PLATFORM\").alias(\"ORIGIN_PLATFORM\"),\n",
    "                col(\"DESTINATION_TIPLOC_CODE\").alias(\"DESTINATION_TIPLOC_CODE\"),\n",
    "                col(\"DESTINATION_DESCRIPTION\").alias(\"DESTINATION_DESCRIPTION\"),\n",
    "                col(\"DESTINATION_LAT_LON\").alias(\"DESTINATION_LAT_LON\"),\n",
    "                col(\"DESTINATION_PUBLIC_ARRIVAL_TIME\").alias(\"DESTINATION_PUBLIC_ARRIVAL_TIME\"),\n",
    "                col(\"DESTINATION_PLATFORM\").alias(\"DESTINATION_PLATFORM\")\n",
    "                )\n",
    "        )\n",
    "\n",
    "tc_iceberg_config = {\n",
    "    \"external_volume\": \"iceberg_hol_gold_vol\",\n",
    "    \"catalog\": \"SNOWFLAKE\",\n",
    "    \"base_location\": f\"hol_user_{usernum}/train_cancellations/\",\n",
    "    \"catalog_sync\": \"iceberg_hol_oc_int\"\n",
    "}\n",
    "\n",
    "# To create a table from this DataFrame:\n",
    "df_tc_l.write.save_as_table(\"TRAIN_CANCELLATIONS\", mode=\"truncate\", iceberg_config = tc_iceberg_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed19c17",
   "metadata": {},
   "source": [
    "# Creating the TOC_MVT_STATS View\n",
    "\n",
    "This step creates a summary view named `TOC_MVT_STATS` that aggregates movement statistics by Train Operating Company (TOC). The view provides counts of movements, unique trains, and time ranges, supporting dashboarding and business intelligence use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3032e3-8653-46b6-b9f3-c34fde831ee8",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "CREATE VIEW IF NOT EXISTS TOC_MVT_STATS AS\n",
    "SELECT TOC,\n",
    "  sum( case when SCHEDULE_KEY = 'no_schedule_activation_found' then 1 else 0 end ) as no_activation_found,\n",
    "  sum( case when SCHEDULE_KEY = 'no_schedule_activation_found' then 0 else 1 end ) as activation_found,\n",
    "  COUNT(*) as MOVEMENT_CT,\n",
    "  COUNT(DISTINCT(train_id)) as unique_trains,\n",
    "  TO_CHAR(\n",
    "  CONVERT_TIMEZONE('UTC', 'Europe/London', TO_TIMESTAMP(min(ACTUAL_TIMESTAMP)/1000)),\n",
    "  'yyyy-MM-dd HH:mm:ss'\n",
    " ) first_ts,\n",
    " TO_CHAR(\n",
    "  CONVERT_TIMEZONE('UTC', 'Europe/London', TO_TIMESTAMP(max(ACTUAL_TIMESTAMP)/1000)),\n",
    "  'yyyy-MM-dd HH:mm:ss'\n",
    " ) last_ts\n",
    "FROM TRAIN_MOVEMENTS\n",
    "GROUP BY TOC;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "7698903671161",
   "authorName": "HOL_USER_999",
   "lastEditTime": 1748579160893,
   "notebookId": "wzfwq7zzqus4phnzdqen",
   "sessionId": "b1b048a4-a48e-4301-95d7-dfe4fcd8cc60"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
