{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "wusisojoicmikbpzqugv",
   "authorId": "9070232501847",
   "authorName": "ADMIN",
   "authorEmail": "",
   "sessionId": "26df5de7-baa2-499d-84af-846e9c76770e",
   "lastEditTime": 1749018245053
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c74ac7ec-8b39-4254-a833-79c1dbe01d22",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "# Set User-Specific Variables\n\nThis section defines variables for your username, role, database, and schema. These variables will be used throughout the notebook to ensure all operations are performed in your dedicated environment."
  },
  {
   "cell_type": "code",
   "id": "c141f040-acc7-4bb4-ac96-d92460087812",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "usernum = str('<INSERT USER NUMBER>')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98da6565-46eb-44b0-a4f3-3f75d9dade39",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": "SET USERNAME = 'HOL_USER_' || {{usernum}};\nSELECT $USERNAME;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "243e142b-81f9-4cf1-95ea-96a8317e70ee",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": "SET HOLROLE = $USERNAME || '_FULL_ROLE';\nSET DB_NAME = $USERNAME || '_DB';\nSET SCHEMANAME = 'GOLD';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e896e64-c3b3-4d78-b7e5-551248531d8e",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "USE ROLE IDENTIFIER($HOLROLE);\nUSE DATABASE IDENTIFIER($DB_NAME);\nUSE SCHEMA IDENTIFIER($SCHEMANAME);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "247d57fd-9562-4ea5-829e-2ddefd36c199",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": "WITH max_time AS (\n  SELECT\n    TO_TIMESTAMP_NTZ(MAX(ACTUAL_TIMESTAMP)/1000) AS max_ts\n  FROM\n    TRAIN_MOVEMENTS\n  WHERE\n    ACTUAL_TIMESTAMP IS NOT NULL\n),\ntime_spine AS (\n  SELECT\n    DATEADD(MINUTE, -seq * 30, (SELECT max_ts FROM max_time)) AS time_bucket\n  FROM (\n    SELECT\n      ROW_NUMBER() OVER (ORDER BY SEQ4()) - 1 AS seq\n    FROM\n      TABLE(GENERATOR(ROWCOUNT => 48))  -- 48 half-hour buckets in last 24 hours\n  )\n)\nSELECT\n  t.time_bucket,\n  m.VARIATION_STATUS AS status,\n  COUNT(*) AS arrival_count\nFROM\n  time_spine AS t\n  LEFT JOIN TRAIN_MOVEMENTS AS m\n    ON TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) >= t.time_bucket\n   AND TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) < DATEADD(MINUTE, 30, t.time_bucket)\n   AND TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) >= DATEADD(HOUR, -24, (SELECT max_ts FROM max_time))\nWHERE\n  m.ACTUAL_TIMESTAMP IS NOT NULL\nGROUP BY\n  1, 2\nORDER BY\n  1, 2;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79629c04-8ead-4132-85c0-0d1e7ceaacde",
   "metadata": {
    "language": "sql",
    "name": "station_arrivals"
   },
   "outputs": [],
   "source": "WITH max_time AS (\n  SELECT\n    TO_TIMESTAMP_NTZ(MAX(ACTUAL_TIMESTAMP)/1000) AS max_ts\n  FROM\n    TRAIN_MOVEMENTS\n  WHERE\n    ACTUAL_TIMESTAMP IS NOT NULL\n),\ntime_spine AS (\n  SELECT\n    DATEADD(MINUTE, -seq * 30, (SELECT max_ts FROM max_time)) AS time_bucket\n  FROM (\n    SELECT\n      ROW_NUMBER() OVER (ORDER BY SEQ4()) - 1 AS seq\n    FROM\n      TABLE(GENERATOR(ROWCOUNT => 48))  -- 48 half-hour buckets in last 24 hours\n  )\n)\nSELECT\n  t.time_bucket,\n  m.VARIATION_STATUS AS status,\n  COUNT(*) AS arrival_count\nFROM\n  time_spine AS t\n  LEFT JOIN TRAIN_MOVEMENTS AS m\n    ON TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) >= t.time_bucket\n   AND TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) < DATEADD(MINUTE, 30, t.time_bucket)\n   AND TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) >= DATEADD(HOUR, -24, (SELECT max_ts FROM max_time))\nWHERE\n  m.ACTUAL_TIMESTAMP IS NOT NULL\nGROUP BY\n  1, 2\nORDER BY\n  1, 2;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "source": "df = station_arrivals.to_pandas()\n# Pivot to have statuses as columns\ndf_pivot = df.pivot(index='TIME_BUCKET', columns='STATUS', values='ARRIVAL_COUNT').fillna(0)\n\n# Optional: Sort by time\ndf_pivot = df_pivot.sort_index()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "995d63b9-cd75-46e0-9638-14e41a03f570",
   "metadata": {
    "name": "cell6"
   },
   "source": "df = station_arrivals.to_pandas()\n# --- HANDLE NULL STATUSES\ndf['STATUS'] = df['STATUS'].fillna('UNKNOWN')\n\n# --- PREPARE FOR ALTAIR\ndf['TIME_BUCKET'] = pd.to_datetime(df['TIME_BUCKET'])\n\n# Altair needs \"long\" format (already is)\nchart = alt.Chart(df).mark_bar().encode(\n    x=alt.X('TIME_BUCKET:T', title='Time (30-min buckets)'),\n    y=alt.Y('ARRIVAL_COUNT:Q', stack='zero', title='Arrival Count'),\n    color=alt.Color('STATUS:N', title='Variation Status'),\n    tooltip=['TIME_BUCKET:T', 'STATUS:N', 'ARRIVAL_COUNT:Q']\n).properties(\n    title='Train Movements by Variation Status (Last 24h)',\n    width=900,\n    height=400\n)\n\n# --- DISPLAY IN STREAMLIT\nst.title(\"Train Arrival Variations\")\nst.altair_chart(chart, use_container_width=True)"
  },
  {
   "cell_type": "code",
   "id": "9856210e-9102-4442-8047-d43346889c54",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "WITH max_time AS (\n  SELECT\n    TO_TIMESTAMP_NTZ(MAX(ACTUAL_TIMESTAMP/1000)) AS max_ts\n  FROM\n    TRAIN_MOVEMENTS\n  WHERE\n    ACTUAL_TIMESTAMP IS NOT NULL\n),\ntime_spine AS (\n  SELECT\n    DATEADD(MINUTE, -seq * 30, (SELECT max_ts FROM max_time)) AS time_bucket\n  FROM (\n    SELECT\n      ROW_NUMBER() OVER (ORDER BY SEQ4()) - 1 AS seq\n    FROM\n      TABLE(GENERATOR(ROWCOUNT => 48))  -- 48 half-hour buckets\n  )\n),\nmovements_with_name AS (\n  SELECT\n    TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) AS actual_ts,\n    m.VARIATION_STATUS,\n    l.NAME AS location_name\n  FROM\n    TRAIN_MOVEMENTS m\n    LEFT JOIN BRONZE.LOCATIONS_RAW l\n      ON m.LOC_STANOX = l.STANOX\n  WHERE\n    m.ACTUAL_TIMESTAMP IS NOT NULL\n)\nSELECT\n  t.time_bucket,\n  m.location_name,\n  m.VARIATION_STATUS AS status,\n  COUNT(*) AS arrival_count\nFROM\n  time_spine AS t\n  LEFT JOIN movements_with_name AS m\n    ON m.actual_ts >= t.time_bucket\n   AND m.actual_ts < DATEADD(MINUTE, 30, t.time_bucket)\n   AND m.actual_ts >= DATEADD(HOUR, -24, (SELECT max_ts FROM max_time))\nGROUP BY\n  1, 2, 3\nORDER BY\n  1, 2, 3;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9de49aed-1595-4482-a678-c1c21b75277f",
   "metadata": {
    "language": "sql",
    "name": "top_stations"
   },
   "outputs": [],
   "source": "WITH max_time AS (\n    SELECT TO_TIMESTAMP_NTZ(MAX(ACTUAL_TIMESTAMP)/1000) AS max_ts\n    FROM TRAIN_MOVEMENTS\n    WHERE ACTUAL_TIMESTAMP IS NOT NULL\n),\nconverted_data AS (\n    SELECT\n        LOC_STANOX,\n        TO_TIMESTAMP_NTZ(ACTUAL_TIMESTAMP/1000) AS actual_ts,\n        TIMETABLE_VARIATION,\n        LATE_IND\n    FROM TRAIN_MOVEMENTS, max_time\n    WHERE ACTUAL_TIMESTAMP IS NOT NULL\n      AND TO_TIMESTAMP_NTZ(ACTUAL_TIMESTAMP/1000) >= DATEADD(HOUR, -24, max_ts)\n),\nbucketed_data AS (\n    SELECT\n        LOC_STANOX,\n        DATEADD(\n            MINUTE,\n            -MOD(DATE_PART('MINUTE', actual_ts), 30),\n            DATE_TRUNC('HOUR', actual_ts)\n        ) AS time_bucket,\n        COUNT(*) AS delay_count\n    FROM converted_data\n    WHERE TIMETABLE_VARIATION > 0 OR LATE_IND = 1\n    GROUP BY LOC_STANOX, time_bucket\n),\ntop_stations AS (\n    SELECT\n        LOC_STANOX,\n        SUM(delay_count) AS total_delay_count\n    FROM bucketed_data\n    GROUP BY LOC_STANOX\n    ORDER BY total_delay_count DESC\n    LIMIT 10\n)\nSELECT\n    b.time_bucket,\n    b.LOC_STANOX,\n    b.delay_count,\n    l.DESCRIPTION\nFROM bucketed_data b\nLEFT JOIN BRONZE.LOCATIONS_RAW l on b.LOC_STANOX = l.STANOX\nJOIN top_stations t ON b.LOC_STANOX = t.LOC_STANOX\nORDER BY b.time_bucket, b.LOC_STANOX;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce638fa2-f645-43b5-ab48-1d2b4ee7a949",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport pandas as pd\nimport altair as alt\n\ndf = top_stations.to_pandas()\n\n\n# Rename columns to lowercase\ndf = df.rename(columns={\n    'TIME_BUCKET': 'time_bucket',\n    'LOC_STANOX': 'loc_stanox',\n    'DELAY_COUNT': 'delay_count',\n    'DESCRIPTION': 'description'\n})\n\n# Convert time_bucket to datetime\ndf['time_bucket'] = pd.to_datetime(df['time_bucket'])\n\n# Optional: show table to debug\nst.dataframe(df)\n\n# Create stacked bar chart\nchart = alt.Chart(df).mark_bar().encode(\n    x=alt.X('time_bucket:T', title='Time (30-min buckets)'),\n    y=alt.Y('delay_count:Q', title='Delay Count'),\n    color=alt.Color('loc_stanox:N', title='Station'),\n    tooltip=['time_bucket:T', 'loc_stanox:N', 'delay_count:Q']\n).properties(\n    width=800,\n    height=400,\n    title=\"Top Stations by Delay (per 30-min buckets)\"\n)\n\nst.altair_chart(chart)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19fe31ff-f041-47fd-ae19-5603a67389b6",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "desc table  BRONZE.LOCATIONS_RAW",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aff8af73-c2e2-44e5-8f66-3e3d0bf0bcb2",
   "metadata": {
    "language": "sql",
    "name": "delayed"
   },
   "outputs": [],
   "source": "WITH max_time AS (\n  SELECT\n    TO_TIMESTAMP_NTZ(MAX(ACTUAL_TIMESTAMP/1000)) AS max_ts\n  FROM\n    TRAIN_MOVEMENTS\n  WHERE\n    ACTUAL_TIMESTAMP IS NOT NULL\n),\ndelay_data AS (\n  SELECT\n    m.LOC_STANOX,\n    m.LATE_IND,\n    m.MVT_LAT_LON:lat::FLOAT AS latitude,\n    m.MVT_LAT_LON:long::FLOAT AS longitude,\n    l.NAME AS station_name,\n    l.tiploc,\n    l.DESCRIPTION\n    \n  FROM\n    TRAIN_MOVEMENTS m\n    LEFT JOIN BRONZE.LOCATIONS_RAW l ON m.LOC_STANOX = l.STANOX,\n    max_time\n  WHERE\n    m.LATE_IND = 1\n    AND m.ACTUAL_TIMESTAMP IS NOT NULL\n    AND m.MVT_LAT_LON IS NOT NULL\n    AND TO_TIMESTAMP_NTZ(m.ACTUAL_TIMESTAMP/1000) >= DATEADD(HOUR, -24, max_ts)\n)\nSELECT * FROM delay_data;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1736743c-5aa8-41fa-81b4-2157fa1984ff",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "import streamlit as st\nimport pandas as pd\nimport streamlit as st\nimport pandas as pd\nimport pydeck as pdk\n\n# Example: Load data from Snowflake\n# df = your_snowflake_cursor.to_pandas()\ndf = delayed.to_pandas()\n\n# Drop nulls in lat/lon\ndf = df.dropna(subset=[\"LATITUDE\", \"LONGITUDE\"])\n\n\n# Ensure the columns are properly named and lat/lon are numeric\ndf = df.dropna(subset=[\"LATITUDE\", \"LONGITUDE\"])\ndf[\"LATITUDE\"] = df[\"LATITUDE\"].astype(float)\ndf[\"LONGITUDE\"] = df[\"LONGITUDE\"].astype(float)\n\n# Display the map\nst.subheader(\"Train delays in the UK (last 24 hours)\")\nst.map(df[[\"LATITUDE\", \"LONGITUDE\"]])\n\n",
   "execution_count": null
  }
 ]
}